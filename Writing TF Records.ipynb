{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When we train the model we should do data loading in tf records too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import tensorflow as tf\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook, tnrange, tqdm\n",
    "\n",
    "from scipy.signal import medfilt2d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper functions for defining tf types\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFolder = '../tgs-salt-identification-challenge/trainData/'\n",
    "testFolder  = '../tgs-salt-identification-challenge/testData/'\n",
    "depthFile = pd.read_csv('../depths.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import ImageReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ids\n",
    "train_ids = next(os.walk(trainFolder +\"images\"))[2]\n",
    "test_ids = next(os.walk(testFolder +\"images\"))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 30/4000 [00:00<00:13, 290.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [00:13<00:00, 305.63it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, depthVals = ImageReader.ReadSegmentationImages(trainFolder, depthFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0#(X_train-X_train_mean)/(2*X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/18000 [00:00<00:51, 347.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting images and masks ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [00:52<00:00, 345.95it/s]\n"
     ]
    }
   ],
   "source": [
    "#loading the final test set too\n",
    "X_test, d_test = ImageReader.ReadSegmentationImages(testFolder, depthFile, readMasks = False)\n",
    "X_test = X_test/255.0 #(X_test-X_train_mean)/(2*X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3840, 101, 101, 1), (160, 101, 101, 1)\n"
     ]
    }
   ],
   "source": [
    "#train test splitting\n",
    "valRatio = 0.04\n",
    "nVal = int(len(X_train)*valRatio)\n",
    "X_val = X_train[0:nVal]\n",
    "Y_val = Y_train[0:nVal]\n",
    "d_val = depthVals[0:nVal]\n",
    "\n",
    "X_train0 = X_train[nVal:]\n",
    "Y_train0 = Y_train[nVal:]\n",
    "d_train0 = depthVals[nVal:]\n",
    "X_train0.shape\n",
    "print('{}, {}'.format(X_train0.shape, X_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsampling\n",
    "X_train0=np.concatenate((X_train0,X_train0,X_train0,X_train0,X_train0),axis=0)\n",
    "Y_train0=np.concatenate((Y_train0,Y_train0,Y_train0,Y_train0,Y_train0),axis=0)\n",
    "d_train0=np.concatenate((d_train0,d_train0,d_train0,d_train0,d_train0),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have the train, validation and final test set, we write these 3 as 3 different tf records. \n",
    "#THe tf record has to entail: The image, the segmentation, the depth and a \"has label\", so we can easily train it together we should\n",
    "#have an empty segmentation mask for the unlabeled ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in loop:\n",
    "def write_segment_rec(image=X_train0,segment=Y_train0,is_train=1,depthfile=d_train0,file_name=\"salty_train.tfrecords\"):\n",
    "    writer = tf.python_io.TFRecordWriter(file_name)\n",
    "    \n",
    "    for j in tqdm(range(image.shape[0])):\n",
    "        img=image[j,:,:,:]\n",
    "        if is_train==1:\n",
    "            annotation=segment[j,:,:,:]\n",
    "        else:\n",
    "            annotation=np.zeros(shape=(101,101,1),dtype=np.int8)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        depth=depthfile[j]\n",
    "        img_raw = img.tostring()\n",
    "        annotation_raw = annotation.tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "                    'height': _int64_feature(height),\n",
    "                    'width': _int64_feature(width),\n",
    "                    'image_raw': _bytes_feature(img_raw),\n",
    "                    'mask_raw': _bytes_feature(annotation_raw),\n",
    "                    \"depth\":_float_feature(depth), \n",
    "                    \"is_train\":_float_feature(is_train)}\n",
    "                                                              \n",
    "                                                             ))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19200/19200 [00:04<00:00, 4798.95it/s]\n"
     ]
    }
   ],
   "source": [
    "write_segment_rec(image=X_train0,segment=Y_train0,is_train=1,depthfile=d_train0,file_name=\"salty_train.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 160/160 [00:00<00:00, 4740.93it/s]\n"
     ]
    }
   ],
   "source": [
    "write_segment_rec(image=X_val,segment=Y_val,is_train=1,depthfile=d_val,file_name=\"salty_valid.tfrecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18000/18000 [00:03<00:00, 4691.93it/s]\n"
     ]
    }
   ],
   "source": [
    "write_segment_rec(image=X_test,segment=None,is_train=0,depthfile=d_test,file_name=\"salty_test.tfrecords\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
